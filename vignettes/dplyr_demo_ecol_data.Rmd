---
title: "Wrangling your data frames with dplyr and tidyr"
author: "Elise Gould"
date: "6 September 2016"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(magrittr)
library(dplyr)
library(tidyr)
library(devtools)
library(ggplot2)
```

# Why dplyr?

Anything you can do in dplyr, you can do in base R. So why bother?

Expressive, and verb-focused rather than object-focused:

- Code is easier to write: less mental effort, more efficient (I have been able to halve the number of lines of code taken to merge and tidy data-frames when translating into dplyr).
- this means it's easy to *read*, which is handy if you're reading other people's code, or some code from a project you haven't looked at in a while.

Computationally efficient:

Many operations are coded in C++, so commands are very fast to execute.

# A grammar of data manipulation:

## *Verbs*:

- row-wise subsetting: `filter()` takes logical conditions as arguments
- column-wise subsetting: `select()` takes column names or `tidyr` functions to select matching columns

- Create new variables, change existing variables: `mutate()`
- summarise data with summary statistics: `summarise()`

- Reorder rows: `arrange()`
- Rename variables: `rename()`

- Writing sentences, connecting your verbs: `%>%` pipe operator for connecting each operation into a pipeline.

## A common syntax:

Each of the verbs above follow the same syntax:

- first argument is a data-frame
- other arguments describe what to do to that data frame, you refer to columns in the data frame directly, no need to use the $ operator
- the function returns a new data frame
- input and output dataframes are *tidy* dataframes


# Manipulating ecological data with `dplyr`: a demo

## About the dataset we'll be using:

This is the field data from my Master's project. Check out the github repository here: [GrasslandAllocatr](https://github.com/egouldo/GrasslandAllocatr). 

a. There is one file containing the raw observations from the field campaign.
b. A second file containing information about all observed vascular species across all sites
c. A third file containing information about management actions undertaken at each site.

## Planning ahead: what do we want to do with this data?

We establish the aims of the mini-analysis:

1. Import and merge the three datasets into a single data frame.
2. Create new variables summarised over each transect
        - mean bare ground per transect
        - mean exotic cover per transect
        - weed diversity at each transect
        - native forb diversity at each transect
3. Do some plotting with our tidy, summarised data

## Get the data:


```{r get-data}
# devtools::install_github("egouldo/GrasslandAllocatr") # uncomment to download the data
library(GrasslandAllocatr)
data("field_data_raw_2014")
data("field_site_management_2014")
data("field_species_lookup_table_2014")
```

Let's check out the structure of the data, there are three data frames:

```{r check-structure}
dplyr::glimpse(field_data_raw_2014)
glimpse(field_site_management_2014)
glimpse(field_species_lookup_table_2014)
```

## Tidying our data

Oh-oh, data was stored incorrectly, and the columns have been merged together... let's fix that:

```{r separate-cols}
field_data <- field_data_raw_2014 %>% 
        tidyr::separate(., 
                        col = transect_number.quadrat.species.percent_cover, 
                        into = c("transect_number", "quadrat", "species", "percent_cover"),
                        sep = ",")  %>% tbl_df()

field_data # neat console output from tbl_df

glimpse(field_data) # That's better

site_management_data <- field_site_management_2014 %>%
        tidyr::separate(.,
                        col = transect_number.size.date.orientation.assistant.management.burn_season.years_since.biomass_reduction_year.management_unit,
                        into = c("transect_number", "size", "date", "orientation", 
                                 "assistant", "management", "burn_season", "years_since", 
                                 "biomass_reduction_year", "management_unit") ,sep = ",") %>% tbl_df()

glimpse(site_management_data) # That's better

species_lookup_table <- field_species_lookup_table_2014 %>%
        tidyr::separate(., 
                        col = species.origin.growth_form.type ,
                        into = c("species", "origin", "growth_form", "type"), sep = ",") %>% tbl_df()

glimpse(species_lookup_table) # That's better

```

So we have three different data frames now:

1. `field_data`: `r unique(field_data$transect_number) %>% length()` transects, and 10 quadrats per each transect. For each quadrat we have percentage cover estimates for individual species, as well as abiotic variables including litter, rock, lichen and bare ground. Note that the variable `species` is a bit of a misnomer because this column contains species names and abiotic variables.
2. `site_management_data`: Contains information about management actions undertaken at each site, and any burning history, such as date and season of last burn (an observation for each transect)
3. `species_lookup_data`: Contains a list of every single vascular species observed across all sites, and the origin (native, exotic), growth form (forb, graminoid).

## Merging data frames: relational data

We want to keep all observations in the `field_data` frame, and we want to add the columns from the `species_lookup_dataframe`, matching by each species. So we want a `left_join()`, which can be graphically represented by:

![left_join, R for datascience](http://r4ds.had.co.nz/diagrams/join-outer.png)

See the section on relational data frames in Wickham and Grolemund's book [R for datascience](http://r4ds.had.co.nz/relational-data.html) for more information about the different types of joins in `dplyr`. 

We also want to merge in site-level management attributes. We'll do the joining in two-steps, and connect them with a pipe.

```{r merge-all-data-frames}
analysis_data <- dplyr::left_join(field_data, species_lookup_table) %>% # this weird operator is a pipe
        dplyr::left_join(.,site_management_data)
analysis_data # after
glimpse(analysis_data) # this is where glimpse comes in handy...
```

## Let's *tidy* up a bit:

### Remove rows using `dplyr::filter()` and cols using `dplyr::select()`

I want to exclude the site that has been slashed from further analysis, we do this with `dplyr::filter()`. I don't really care about the `origin` or `growth_form` variables, because `type` is an amalgam of these two variables for vascular species, but contains entries for abiotic measures like rock and bare-ground, which is also important. Let's drop this using `dplyr::select()`. We can join both of these two operations together into a pipeline, using the pipe operator `%>%`. 

```{r remove-row-remove-cols}
analysis_data %<>% 
        dplyr::filter(management != "Slashing_WC") %>%
        dplyr::select(-growth_form,-origin)
analysis_data %>% glimpse
```

The pipe operator sends the object on the left as the first argument to the commands on the right. We can chain multiple operations together with multiple pipes. The `%<>%` is a special version of the pipe operator from package `magrittr`, it sends the transformed object back and assigns it to the object's name, in this case `analysis_data`

### Change existing variables using `dplyr::mutate()`

Unfortunately there was no information about non-vascular species in the 'type' column that came from the `species_lookup_table` dataframe. We want information about the type of every recorded entity in each quadrat in this column. So far we only have information about vascular plants. 

We use `dplyr::mutate` to manipulate existing variables. We can incorporate `ifelse` statements to assign the output to the column we want to manipulate conditionally. Below we want to set the type to "bare ground" or `"BG"` if there is an observation of "BG" in the `species` column.

```{r set-type-for-non-vascular-species}
analysis_data %<>%
        dplyr::mutate(type = ifelse(species == "BG", "BG", type),
                      type = ifelse(species == "L", "L", type),
                      type = ifelse(species == "LM", "LM", type),
                      type = ifelse(species == "R", "R", type))


```

Also, when we loaded our dataframes in from the package, all variables were stored as character variables. We want to change the following variables to:

1. `percent_cover` -> double
2. `size` -> double
3. `date` -> date-format
4. `management` -> factor
5. `years_since` last biomass removal -> double
6. `transect_number` and `quadrat` -> integer

Again, we manipulate existing variables using `dplyr::mutate`

```{r change-variable-types}
analysis_data %<>%
        dplyr::mutate(percent_cover = as.double(percent_cover),
                      size = as.double(size),
                      date = lubridate::as_date(date),
                      management = as.factor(management),
                      years_since = as.double(years_since),
                      transect_number = as.integer(transect_number),
                      quadrat = as.integer(quadrat))

```


## Now let's *transform* our data:

We want to create following summary variables, one for every single transect:

-  `BG_pc` Mean percent cover of bare-ground (`type == "BG`"), for each transect
-  `E_pc` Mean percent cover of all exotic species (`type == "E`), for each transect
-  `E_diversity` Number of all exotic species at each transect (sum of all `"E"` spp across quadrats)
-  `NF_diversity` Number of native forbs (`type == "BG"`)


### Grouped operations with `dplyr::group_by()`:

The `dplyr::group_by` function is the star of the show here, and we can avoid for-loops when we want to repeat the same operation on subsets or groups of a dataframe. This is particularly handy when we have nested grouping.

For example, the first two variables we want to create require that we `group_by` each transect, *then* each quadrat, *then* each type. The second set of variables require that we group by `transect` and `type` only: we want to know how many unique species occurred in each transect, for both exotic and native forbs.

We'll create each type of variable separately, starting with the percent cover variables:

```{r make-summary-vars}
analysis_data %>%
        dplyr::group_by(transect_number, quadrat, type) %>%
        dplyr::summarise(pc_type = sum(percent_cover)) # Gives us the percent cover for each type, in each quadrat

# now we want to take the mean of the type percent cover totals, over all quadrats, let's try again:
mean_percent_cover <- 
        analysis_data %>%
        group_by(transect_number, quadrat, type) %>%
        summarise(pc_type = sum(percent_cover)) %>%
        group_by(transect_number,type) %>%
        summarise(mean_pc_type = mean(pc_type))

mean_percent_cover

# But we only want the mean percent cover for the exotic species, and the native forbs:
# AND, we want them to be in separate columns.

mean_percent_cover %<>%
        tidyr::spread(., key = type, value = mean_pc_type) %>%
        select(transect_number, BG, E) %>%
        dplyr::rename(., E_pc = E, BG_pc = BG)

mean_percent_cover
        
```

Okay, onto the diversity variables now:

```{r diversity-variables}
# Let's get the number of distinct species of Ecotics and Native Forbs, within each transect
diversity_vars <-
        analysis_data %>%
        filter(type == "NF" | type == "E") %>%
        group_by(transect_number, type) %>%
        distinct(species) %>%
        tally

# Let's get this into an appropriate shape for joining this onto the percent cover data:
diversity_vars

```

Let's join these two data frames back together:

```{r join-all-summary-vars}
diversity_vars %<>%
        spread(key = type, value = n) %>%
        rename(E_diversity = E, NF_diversity = NF)
diversity_vars
```

But wait, we're missing the site level data, which are our explanatory variables.Let's first join the two data frames containing our response variables together, and then join it back in. Notice how we can pipe each of these actions together into a single pipeline.

```{r create-diversity-vars}

summary_vars <- left_join(mean_percent_cover, diversity_vars) %>%
        left_join(.,{analysis_data %>% 
                        select(transect_number,management,years_since) %>%
        distinct})

```


## Our data's ready for analysis now, make some plots:

Because we've been 'tidying' our data as we go, we can send it straight to ggplot2, for some nice plots.

```{r ggplots, fig.height= 6, fig.width=8}
summary_vars %>%
        ggplot(aes(x = management, y = BG_pc)) +
        geom_violin() +
        geom_point()

summary_vars %>%
        ggplot(aes(x = years_since, y = BG_pc, colour = management)) +
        geom_point()

```


That's nice. But I wonder how each of the variables vary in relation to one another? We'll use faceting in ggplot2, so we'll need to make our data long.

```{r faceted-violins,fig.width=10, fig.height=8}

summary_vars %>% 
        gather(key = variable, value = value, BG_pc,E_pc,E_diversity,NF_diversity) %>%
        ggplot(aes(x = management, y = value, colour = management)) +
        geom_violin() +
        geom_point()+
        facet_grid(.~variable)

```

That's all folks!

# Session Info:

```{r session-info}
sessionInfo()
```

