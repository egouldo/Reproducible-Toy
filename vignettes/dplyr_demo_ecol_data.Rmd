---
title: "Wrangling your data frames with dplyr"
author: "Elise Gould"
date: "6 September 2016"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(magrittr)
library(dplyr)
library(tidyr)
```

# Why dplyr?

Anything you can do in dplyr, you can do in base R. So why bother?

Expressive, and verb-focused rather than object-focused:

- Code is easier to write: less mental effort, more efficient (I have been able to halve the number of lines of code taken to merge and tidy data-frames when translating into dplyr).
- this means it's easy to *read*, which is handy if you're reading other people's code, or some code from a project you haven't looked at in a while.

Computationally efficient:

Many operations are coded in C++, so commands are very fast to execute.

# A grammar of data manipulation:

## *Verbs*:

- row-wise subsetting: `filter()` takes logical conditions as arguments
- column-wise subsetting: `select()` takes column names or `tidyr` functions to select matching columns

- Create new variables, change existing variables: `mutate()`
- summarise data with summary statistics: `summarise()`

- Reorder rows: `arrange()`
- Rename variables: `rename()`

- Writing sentences, connecting your verbs: `%>%` pipe operator for connecting each operation into a pipeline.

## A common syntax:

Each of the verbs above follow the same syntax:

- first argument is a data-frame
- other arguments describe what to do to that data frame, you refer to columns in the data frame directly, no need to use the $ operator
- the function returns a new data frame
- input and output dataframes are *tidy* dataframes


# Manipulating ecological data with `dplyr`: a demo

## About the dataset we'll be using:

This is my field data from my Master's project. Check out the github repository here: [GrasslandAllocatr](https://github.com/egouldo/GrasslandAllocatr). 

        a. There is one file containing the observations from the field campaign.
        b. Another file containing information about all observed vascular species across all sites
        c. A third file containing information

## What do we want to do with this data?

We establish the aims of the upcoming mini-analysis:

1. Import and merge three CSV files into a single data frame.
2. Create new variables summarised over each transect
        - mean bare ground per transect
        - mean exotic cover per transect
        - weed diversity at each transect
        - native forb diversity at each transect

## Get the data:


```{r get-data}
# library(devtools)
# devtools::install_github("egouldo/GrasslandAllocatr")
library(GrasslandAllocatr)
data("field_data_raw_2014")
data("field_site_management_2014")
data("field_species_lookup_table_2014")
```

Let's check out the structure of the data, there are three data frames:

```{r check-structure}
dplyr::glimpse(field_data_raw_2014)
glimpse(field_site_management_2014)
glimpse(field_species_lookup_table_2014)
```

## Tidying our data

Oh-oh, data was stored incorrectly, and the columns have been merged together... let's fix that:

```{r separate-cols}
field_data <- field_data_raw_2014 %>% 
        tidyr::separate(., 
                        col = transect_number.quadrat.species.percent_cover, 
                        into = c("transect_number", "quadrat", "species", "percent_cover"),
                        sep = ",")  %>% tbl_df()

glimpse(field_data) # That's better

site_management_data <- field_site_management_2014 %>%
        tidyr::separate(.,
                        col = transect_number.size.date.orientation.assistant.management.burn_season.years_since.biomass_reduction_year.management_unit,
                        into = c("transect_number", "size", "date", "orientation", 
                                 "assistant", "management", "burn_season", "years_since", 
                                 "biomass_reduction_year", "management_unit") ,sep = ",") %>% tbl_df()

glimpse(site_management_data) # That's better

species_lookup_table <- field_species_lookup_table_2014 %>%
        tidyr::separate(., 
                        col = species.origin.growth_form.type ,
                        into = c("species", "origin", "growth_form", "type"), sep = ",") %>% tbl_df()

glimpse(species_lookup_table) # That's better

```

So we have three different data frames now:

1. `field_data`: `r unique(field_data$transect_number) %>% length()` transects, and 10 quadrats per each transect. For each quadrat we have percentage cover estimates for individual species, as well as litter, rock, lichen and bare ground. Note that the variable `species` is a bit of a misnomer because this column contains species names and abiotic variables.
2. `site_management_data`: Contains information about management actions undertaken at each site, and any burning history, such as date and season of last burn.
3. `species_lookup_data`: Contains a list of every single vascular species observed across all sites, and the origin (native, exotic), growth form (forb, graminoid).

## Merging data frames: relational data

```{r merge-all-data-frames}
analysis_data <- dplyr::left_join(field_data, species_lookup_table) %>% # this weird operator is a pipe
        dplyr::left_join(.,site_management_data)
```

## Let's *tidy* up a bit:

### Remove rows using `dplyr::filter()` and cols using `dplyr::select()`

I want to exclude the site that has been slashed from further analysis, we do this with `dplyr::filter()`. I don't really care about the `origin` or `growth_form` variables, because `type` is an amalgam of these two variables for vascular species, but contains entries for abiotic measures like rock and bare-ground, which is also important. Let's drop this using `dplyr::select()`. We can join both of these two operations together into a pipeline, using the pipe operator `%>%`.

```{r remove-row-remove-cols}
analysis_data %<>% 
        dplyr::filter(management != "Slashing_WC") %>%
        dplyr::select(-growth_form,-origin)
analysis_data %>% glimpse
```

### Change existing variables using `dplyr::mutate()`

Unfortunately there was no information about non-vascular species in the 'type' column that came from the `species_lookup_table` dataframe. We want information about the type of every recorded entity in each quadrat in this column. So far we only have information about vascular plants. 

```{r set-type-for-non-vascular-species}
analysis_data %<>%
        dplyr::mutate(type = ifelse(species == "BG", "BG", type),
                      type = ifelse(species == "L", "L", type),
                      type = ifelse(species == "LM", "LM", type),
                      type = ifelse(species == "R", "R", type))
```

Also, when we loaded our dataframes in from the package, all variables were stored as character variables. We want to change the following variables to:

1. `percent_cover` -> double
2. `size` -> double
3. `date` -> date-format
4. `management` -> factor
5. `years_since` last biomass removal -> double
6. `transect_number` and `quadrat` -> integer

Again, we manipulate existing variables using `dplyr::mutate`

```{r change-variable-types}
analysis_data %<>%
        dplyr::mutate(percent_cover = as.double(percent_cover),
                      size = as.double(size),
                      date = lubridate::as_date(date),
                      management = as.factor(management),
                      years_since = as.double(years_since),
                      transect_number = as.integer(transect_number),
                      quadrat = as.integer(quadrat))

```


## Now let's *transform* our data:

We want to create following variables:
-  `BG_pc` Mean percent cover of bare-ground (`type == "BG`"), for each transect
-  `E_pc` Mean percent cover of all exotic species (`type == "E`), for each transect
-  `E_diversity` Number of all exotic species at each transect (sum of all `"E"` spp across quadrats)
-  `NF_diversity` Number of native forbs (`type == "BG"`)


### Grouped operations with `dplyr::group_by()`:

The `dplyr::group_by` function is the star of the show here, and we can avoid for-loops when we want to repeat the same operation on subsets or groups of a dataframe.

It also allows for nested grouping. For example, the first two variables require that we `group_by` each transect, *then* each quadrat, *then* each type. The second set of variables require that we group by `transect` and `type` only: we want to know how many unique species occurred in each transect, for both exotic and native forbs.

We'll create each type of variable separately, starting with the percent cover variables:

```{r make-summary-vars}
analysis_data %>%
        dplyr::group_by(transect_number, quadrat, type) %>%
        dplyr::summarise(pc_type = sum(percent_cover))# Gives us the percent cover for each type, in each quadrat

# now we want to take the mean of the type percent cover totals, over all quadrats, let's try again:
mean_percent_cover <- analysis_data %>%
        group_by(transect_number, quadrat, type) %>%
        summarise(pc_type = sum(percent_cover)) %>%
        group_by(transect_number,type) %>%
        summarise(mean_pc_type = mean(pc_type))

# But we only want the mean percent cover for the exotic species, and the native forbs:
# AND, we want them to be in separate columns.

mean_percent_cover %<>%
        tidyr::spread(., key = type, value = mean_pc_type) %>%
        select(transect_number, BG, E) %>%
        dplyr::rename(., E_pc = E, BG_pc = BG)

        
```

Okay, onto the diversity variables now:

```{r diversity-variables}
# Let's get the number of distinct species of Ecotics and Native Forbs, within each transect
!

# Let's get this into an appropriate shape for joining this onto the percent cover data:
diversity_vars

```

Let's join these two data frames back together:

```{r join-all-summary-vars}
diversity_vars %<>%
        spread(key = type, value = n) %>%
        rename(E_diversity = E, NF_diversity = NF)
```

But wait, we're missing the site level data, which are our explanatory variables. Let's join it back in:

```{r create-diversity-vars}

summary_vars <- left_join(mean_percent_cover, diversity_vars)

```



!## Our data's ready for analysis now, make some plots:

because our data is already 'tidy', we can send it straight to ggplot2, for some sweet as plots.



# Session Info:

```{r session-info}
sessionInfo()
```

